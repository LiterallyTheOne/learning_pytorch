{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer learning with MobileNetv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from torch.utils.data import DataLoader, ConcatDataset \n",
    "\n",
    "import torchvision\n",
    "\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def prepare_and_get_data_path(where_is_running: str = 'colab'):\n",
    "    match where_is_running:\n",
    "        case 'colab':\n",
    "            from google.colab import userdata\n",
    "            import os\n",
    "\n",
    "            kaggle_target_path = Path('/root/.kaggle/kaggle.json')\n",
    "\n",
    "            kaggle_target_path.parent.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "            with open(kaggle_target_path, 'w') as f:\n",
    "                f.write(userdata.get('Kaggle'))\n",
    "\n",
    "            os.system('kaggle datasets download -d fruits-100')\n",
    "            os.system('unzip -q fruits-100.zip -d fruits-100')\n",
    "            os.system('rm -r fruits-100.zip')\n",
    "\n",
    "            data_path = Path('fruits-100')\n",
    "\n",
    "        case 'pc':\n",
    "            data_path = Path(\n",
    "                '/home/ramin/ramin_programs/files/datasets/fruits-100')\n",
    "\n",
    "        case 'kaggle':\n",
    "            data_path = Path('fruits-100')\n",
    "\n",
    "    return data_path\n",
    "\n",
    "\n",
    "def find_device():\n",
    "    device = 'cpu'\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        device = 'cuda'\n",
    "    elif torch.backends.mps.is_available():\n",
    "        device = 'mps'\n",
    "\n",
    "    return device\n",
    "\n",
    "\n",
    "def load_train_data(data_path: Path) -> DataLoader:\n",
    "\n",
    "    tr = v2.Compose([\n",
    "        v2.Resize([90, 160]),\n",
    "        v2.ToTensor(),]\n",
    "    )\n",
    "\n",
    "    tr_augmented = v2.Compose(\n",
    "        [v2.RandomHorizontalFlip(),\n",
    "         v2.RandomVerticalFlip(),\n",
    "         v2.RandomZoomOut(),\n",
    "         v2.Resize([90, 160]),\n",
    "         v2.ToTensor(),]\n",
    "    )\n",
    "\n",
    "    image_folder = torchvision.datasets.ImageFolder(\n",
    "        data_path, transform=tr)\n",
    "\n",
    "    image_folder_augmented = torchvision.datasets.ImageFolder(\n",
    "        data_path, transform=tr_augmented)\n",
    "\n",
    "    both_d = ConcatDataset([image_folder, image_folder_augmented])\n",
    "\n",
    "    data_loader = DataLoader(both_d, batch_size=32, shuffle=True)\n",
    "\n",
    "    return data_loader\n",
    "\n",
    "\n",
    "def load_valid_data(data_path: Path) -> DataLoader:\n",
    "    tr = v2.Compose([\n",
    "        v2.Resize([90, 160]),\n",
    "        v2.ToTensor(),]\n",
    "    )\n",
    "\n",
    "\n",
    "    valid_image_folder = torchvision.datasets.ImageFolder(\n",
    "        data_path, transform=tr)\n",
    "\n",
    "    val_data_loader = DataLoader(\n",
    "        valid_image_folder, batch_size=32, shuffle=True)\n",
    "\n",
    "    return val_data_loader\n",
    "\n",
    "\n",
    "def load_model(device: str = 'cuda') -> nn.Module:\n",
    "    model = torchvision.models.mobilenet_v2(\n",
    "        weights=torchvision.models.MobileNet_V2_Weights.IMAGENET1K_V1)\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    model.classifier[1] = nn.Linear(1280, 100)\n",
    "    model = model.to(device)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def train(model: nn.Module, data_loader: DataLoader, loss_fn: nn.Module, optimizer: torch.optim.Optimizer,\n",
    "          device: str = 'cuda', tensorboard_writer=None, epoch: int = 0):\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "\n",
    "    running_loss = 0\n",
    "    i_c = 0\n",
    "    number_of_batches = len(data_loader)\n",
    "\n",
    "    for i, (images, labels) in enumerate(data_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        prediction = model(images)\n",
    "        loss = loss_fn(prediction, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        i_c += 1\n",
    "        if (i % 10 == 9) or i == number_of_batches - 1:\n",
    "            print(\n",
    "                f'\\r{i + 1}/{number_of_batches}, loss = {loss.item():>4f}', end='')\n",
    "            if tensorboard_writer:\n",
    "                tensorboard_writer.add_scalar(\n",
    "                    'training loss', running_loss / i_c, epoch * number_of_batches + i)\n",
    "            running_loss = 0\n",
    "            i_c = 0\n",
    "    print()\n",
    "\n",
    "\n",
    "def evaluate(model: nn.Module,\n",
    "             data_loader: torch.utils.data.DataLoader,\n",
    "             loss_fn: nn.Module,\n",
    "             device: str = 'cuda') -> tuple[torch.float, torch.float]:\n",
    "\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    data_size = len(data_loader.dataset)\n",
    "    number_of_batches = len(data_loader)\n",
    "\n",
    "    loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in data_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            prediction = model(images)\n",
    "            loss += loss_fn(prediction, labels).item()\n",
    "            correct += (prediction.argmax(1) ==\n",
    "                        labels).type(torch.float).sum().item()\n",
    "\n",
    "        loss /= number_of_batches\n",
    "        correct /= data_size\n",
    "\n",
    "    return correct, loss\n",
    "\n",
    "\n",
    "def predict(model: nn.Module,\n",
    "            test_data_path: Path,\n",
    "            device: str = 'cuda') -> pd.DataFrame:\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    tr = torchvision.transforms.Compose(\n",
    "        [torchvision.transforms.Resize(\n",
    "            [90, 160]), torchvision.transforms.ToTensor(), ]\n",
    "    )\n",
    "\n",
    "    image_paths = test_data_path.rglob('*.jpg')\n",
    "\n",
    "    result = {'image_path': [], 'prediction': []}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for image_path in image_paths:\n",
    "            image = Image.open(image_path)\n",
    "\n",
    "            image_tensor = tr(image).to(device)\n",
    "            image_tensor = image_tensor.unsqueeze(0)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                prediction = model(image_tensor)\n",
    "            prediction = torch.argmax(prediction)\n",
    "\n",
    "            result['image_path'].append(\n",
    "                f'{image_path.parent.name} / f{image_path.name}')\n",
    "            result['prediction'].append(prediction.detach().cpu().numpy())\n",
    "\n",
    "    return pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter('runs/tom_and_jerry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "device = find_device()\n",
    "\n",
    "print(f'device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "data_path = prepare_and_get_data_path('pc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "train_data_loader = load_train_data(data_path/'train')\n",
    "valid_data_loader = load_valid_data(data_path/'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "for tensor_image, label in train_data_loader:\n",
    "    figure, axes = plt.subplots(1,1)\n",
    "\n",
    "    axes.imshow(torchvision.transforms.ToPILImage()(tensor_image[0]))\n",
    "    axes.set_axis_off()\n",
    "    print(label[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "model = load_model(device)\n",
    "model = model.to(device)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "for epoch in range(5):\n",
    "      print(f'in epoch: {epoch}')\n",
    "      train(model, train_data_loader, loss_fn, optimizer, device)\n",
    "      accuracy, loss = evaluate(model, valid_data_loader, loss_fn, device)\n",
    "      print(f'validation -> accuracy: {accuracy:.2f}, loss: {loss:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = predict(model, data_path/'test', device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
